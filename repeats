#!/usr/bin/env python
"""
Prints paths of identical files to stdout, separated by tab (\t).

How it works
------------
The script calculates the MD5 checksums of all the files of the same size
underneath the base path I use as my argument. If these MD5s match, the path
is printed.

How to use it
-------------
### List identical pictures in my album.
    $ ./repeats ~/album
        ~/album/_import/IMG_0034.JPG	~/album/my-trip/IMG_0034.JPG
"""
import argparse
import hashlib
import os
import os.path
import time
from collections import defaultdict


DEFAULT_DELIMINER = "\t"
PROFILE_MODE = False


def main(where, deliminer):
    for line in repeats(where, deliminer):
        print(line)


def repeats(where, deliminer):
    all_files = list(get_all_files(where))
    groups = [all_files]
    groups = by_size(groups)
    groups = by_first_bytes(groups)
    groups = by_md5(groups)
    matches = groups
    for same_list in matches:
        yield(deliminer.join(same_list))


def get_all_files(where):
    filerecords = os.walk(where)
    for dirpath, dirnames, filenames in filerecords:
        for name in filenames:
            yield os.path.join(dirpath, name)


def timer(func):
    if not PROFILE_MODE:
        return func

    def timer_wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        finish = time.time()
        duration = finish - start
        print "%s took %s" % (func.__name__, duration)
        return result

    return timer_wrapper


@timer
def by_size(candidates):
    return apply_limiter(candidates, os.path.getsize)


@timer
def by_first_bytes(candidates):
    return apply_limiter(candidates, get_first_bytes)


@timer
def by_md5(candidates):
    return apply_limiter(candidates, calculate_md5)


def get_first_bytes(path):
    BUFFER_SIZE = 1024 * 8
    with open(path) as openfile:
        return openfile.read(BUFFER_SIZE)


def calculate_md5(path):
    """
    Returns the MD5 hash for a file at ``path``.
    """
    md5 = hashlib.md5()
    with open(path) as openfile:
        while True:
            buf = openfile.read(128)
            if not buf:
                break
            md5.update(buf)
    return md5.hexdigest()


def apply_limiter(groups_of_possible_matches, limiter):
    results = []
    for possible_match in groups_of_possible_matches:
        new_elements = group_by(possible_match, limiter).values()
        for element in new_elements:
            if len(element) > 1:
                results.append(element)
    return results


def group_by(iterable, keyfunc):
    groups = defaultdict(list)
    for iterated in iterable:
        result = keyfunc(iterated)
        groups[result].append(iterated)
    return groups


def get_args():
    parser = argparse.ArgumentParser(
        description='finds files with identical contents')
    parser.add_argument(
        '-d', '--deliminer', type=str, default=DEFAULT_DELIMINER,
        help='deliminer between matching filenames')
    parser.add_argument('directory',
            type=str,
            help='location',
            default='.',
            )
    return parser.parse_args()


if __name__ == "__main__":
    args = get_args()
    main(where=args.directory,
         deliminer=args.deliminer,
         )
